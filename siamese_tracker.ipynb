{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One GPU strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "# get available GPU\n",
    "devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(devices[0], True)\n",
    "gpu_name = \"GPU:0\"\n",
    "print(devices[0])\n",
    "\n",
    "# Only one gpu available to set to OneDeviceStrategy \n",
    "# Can be changed to MirroredStrategy if multiple GPU available\n",
    "strategy = tf.distribute.OneDeviceStrategy(device=gpu_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get VOC 2012 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get voc 2012 dataset\n",
    "splits = ['train[:80%]', 'train[80%:90%]', 'train[90%:]']\n",
    "\n",
    "(train_examples, validation_examples, test_examples), info = tfds.load('voc/2012', batch_size=32, with_info=True, split=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeaturesDict({\n",
       "    'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
       "    'image/filename': Text(shape=(), dtype=tf.string),\n",
       "    'labels': Sequence(ClassLabel(shape=(), dtype=tf.int64, num_classes=20)),\n",
       "    'labels_no_difficult': Sequence(ClassLabel(shape=(), dtype=tf.int64, num_classes=20)),\n",
       "    'objects': Sequence({\n",
       "        'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),\n",
       "        'is_difficult': tf.bool,\n",
       "        'is_truncated': tf.bool,\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=20),\n",
       "        'pose': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),\n",
       "    }),\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train examples: 5717, number of labels: 20\n"
     ]
    }
   ],
   "source": [
    "num_examples = info.splits['train'].num_examples\n",
    "num_classes = info.features['labels'].num_classes\n",
    "print(f\"Number of train examples: {num_examples}, number of labels: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess VOC2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize and normalize images\n",
    "@tf.function\n",
    "def format_image(tensor):\n",
    "    images = tf.image.resize(tensor['image'], IMAGE_SIZE) / 255.0\n",
    "    return images, tf.one_hot(tensor['objects']['label'], 20), tensor['objects']['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = num_examples\n",
    "EPOCHS = 10\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "BATCH_SIZE_PER_REPLICA = 32\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare batches\n",
    "BATCH_SIZE = 32\n",
    "train_batches = train_examples.shuffle(num_examples // 4).map(format_image).prefetch(1)\n",
    "validation_batches = validation_examples.map(format_image)\n",
    "test_batches = test_examples.map(format_image).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: (32, 224, 224, 3)\n",
      "Labels shape: (32, 11, 20) and boxes shape: (32, 11, 4)\n"
     ]
    }
   ],
   "source": [
    "for batch, labels, boxes in train_batches:\n",
    "     break\n",
    "print(f\"Batch shape: {batch.shape}\")\n",
    "print(f\"Labels shape: {labels.shape} and boxes shape: {boxes.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribute dataset over GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_datasets(strategy, train_batches, validation_batches, test_batches):\n",
    "    train_dist_dataset = strategy.experimental_distribute_dataset(train_batches)\n",
    "    val_dist_dataset = strategy.experimental_distribute_dataset(validation_batches)\n",
    "    test_dist_dataset = strategy.experimental_distribute_dataset(test_batches)\n",
    "\n",
    "    return train_dist_dataset, val_dist_dataset, test_dist_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.distribute.input_lib.DistributedDataset'>\n"
     ]
    }
   ],
   "source": [
    "train_dist_dataset, val_dist_dataset, test_dist_dataset = distribute_datasets(strategy, train_batches, validation_batches, test_batches)\n",
    "print(type(train_dist_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: (32, 224, 224, 3)\n",
      "Labels shape: (32, 8, 20) and boxes shape: (32, 8, 4)\n"
     ]
    }
   ],
   "source": [
    "for batch, labels, boxes in train_dist_dataset:\n",
    "    break\n",
    "print(f\"Batch shape: {batch.shape}\")\n",
    "print(f\"Labels shape: {labels.shape} and boxes shape: {boxes.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
